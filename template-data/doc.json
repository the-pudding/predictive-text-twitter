{"hed":"What text prediction teaches us about language","intro":[{"type":"text","value":"If you have ever typed something on a smartphone, you have used text prediction. But how does that really work? In this article, we will show you how text predictors can work and discuss how crucial the example language dataset is for the resulting predictions. To see how this all works, we will try to predict tweets by four of the most followed Twitter users: Barack Obama, Justin Timberlake, Kim Kardashian, and Lady Gaga."},{"type":"text","value":"<strong>A Quick Primer on Text Prediction</strong>"},{"type":"text","value":"To be able to make useful predictions, a text predictor needs as much knowledge about language as possible, often done by <em>machine learning</em>. These days, machine learning algorithms called <em>neural networks</em> are the best at text prediction because of their remarkable ability to <a target=_blank href=http://bionlp-www.utu.fi/wv_demo/>capture meaning in a list of numbers</a> and to learn about the <a target=_blank href=https://chunml.github.io/ChunML.github.io/project/Creating-Text-Generator-Using-Recurrent-Neural-Network/>hierarchical levels of language</a>. The downside is that they can be pretty difficult to grasp. Understanding why neural networks do the things they do is a <a target=_blank href=https://distill.pub/2018/building-blocks/>whole research field unto itself</a>."},{"type":"text","value":"There are surprisingly effective machine learning techniques that are much simpler, so we can examine what is happening under the hood. We will start by looking at the <em>k Nearest Neighbours</em> algorithm. This works by looking at the last few words you wrote, comparing these to all groups of words seen during the training phase, and outputs the best guess of what followed groups of similar words in the past."},{"type":"text","value":"Below you can play around with <em>k Nearest Neighbours</em> to predict tweet text. After you chose a person and an example tweet, you can move the slider to various positions in the text, and it will automatically detect the last <em>trigram</em> (group of three words). Next, it will try to find similar trigrams in its database (which was created based on all tweets by that person) and display that along with the word that most often followed this trigram."}],"textblock2-before":[{"type":"text","value":"This approach to text prediction is called <em>context sensitive</em>. A downside of this technique is that there often is no similar group of words available to make a prediction. To go from this to a text predictor that would be good enough to be used in practice, we need two more things:"}],"textblock2-bullets":[{"text":"A list of words frequently used by the author, to be used as a backup."},{"text":"Limiting the pool of probable predictions based on what the user already typed so far. For example, it makes no sense to predict a word like “the” if the user already started typing “ca.”"}],"textblock2-after":[{"type":"text","value":"The resulting predictor is based on what you could call a very simple statistical language model. It is built entirely of example language data: if you put in different data, you get another model with other predictions. You can see that clearly if you let the models of our four celebrities predict each other’s tweets:"}],"textblock3":[{"type":"text","value":"You’ll notice that the model using the same author’s data is the one that makes the correct prediction most often. This follows the general phenomenon in machine learning that the more similar the training data is to the production data, the better the results will be. Put simply, nobody writes more like you than you, so you are your own best language predictor."},{"type":"text","value":"Instead of eyeballing which model works better, we can actually measure it and count the number of correctly guessed characters. You could argue that we are too harsh on ourselves if we count this way, as most language prediction apps give multiple options, but it is a good approximation to compare language models. The percentages below can serve as boundaries of what is possible with this technique."}],"textblock4-before":[{"type":"text","value":"Again you’ll see that the more similar two Twitter users are, the more likely they are to correctly predict each other's tweets. It makes sense that artists Justin Timberlake and Lady Gaga are each other's best predictors. Barack Obama and Kim Kardashian, on the other hand, are each other's worst predictors. If we want to guess what a person is going to write next, our best guess is something similar to what this same person has written in the past."},{"type":"text","value":"It is interesting to note that the statements above are not true for individual tweets. For example, Kim Kardashian's tweet about “working together with organizations” was predicted better by the language model of Barack Obama than her own. In other words, “You are your own best language predictor” is more of a tendency than a hard rule."},{"type":"text","value":"Our example users so far have been really active Twitter users with thousands of tweets. But how do we solve for people with less data? The research field of sociolinguistics has the answer: look to the language from the people around you. It is commonly accepted that people who talk to each other a lot tend to speak more alike, an idea that could be very useful in this case."},{"type":"text","value":"We can simulate this effect on Twitter by following @ mentions as a loose proxy for “people who talk to each other a lot.” These are the conversation participants of our four Twitter users that they mentioned most frequently (more than 10 times):"}],"textblock4-bullets":[{"name":"BarackObama","text":"@VP (17 mentions)"},{"name":"jtimberlake","text":"@ChrisStapleton (16 mentions), @AnnaKendrick47 (15 mentions), @jimmyfallon (15 mentions)"},{"name":"KimKardashian","text":"@MakeupByMario (18 mentions), @khloekardashian (13 mentions)"},{"name":"ladygaga","text":"@itstonybennett (30 mentions), @MarkRonson (16 mentions), @faspiras (15 mentions)"}],"textblock4-after":[{"type":"text","value":"These Twitter “friends” are of course highly dependent on the way Twitter is used; whereas Lady Gaga and Justin Timberlake often address colleagues and other celebrities, Barack Obama almost exclusively uses Twitter address larger groups of people."},{"type":"text","value":"Let’s take a look at how these “friend” models perform."}],"closing":[{"type":"text","value":"As you can see, the “friend” models are ranked directly after the personal models in almost all cases. Part of this effect can of course be explained by overlapping topics; the models of Justin Timberlake and Lady Gaga are probably good at predicting each other’s tweets because they are both tweeting about things like songs, concerts and fans. Something similar is likely happening with the predictions of @VP (Vice President) for the tweets of Obama. Although Obama only mentioned @VP when it was still being used by Joe Biden, the tweets of current Vice President Mike Pence are still good predictors because of their political nature. However, overlapping topics are not the whole story. Research has shown that even if you take out all content words, leaving only words like “the”, “but”, “and”, “is”, etc., <a target=_blank href=http://www.aclweb.org/anthology/E/E14/E14-1034.pdf>tweets by friends are still better</a> <a target=_blank href=https://www.narcis.nl/publication/RecordID/oai%3Arepository.ubn.ru.nl%3A2066%2F155926/coll/person/id/5/Language/en>predictors than tweets by random people</a>."},{"type":"text","value":"Note that this technique makes it possible to make predictions of what somebody wants to say even if we have no previous material of a particular person at all. This can be the case if somebody has word finding problems (aphasia) or cannot move their speech organs (for example because of paralysis). A word predictor can be of great help to such a person, and can be trained with the language of the people around them. This idea is called “language transplantation”."},{"type":"text","value":"So there you have it: we have seen a simple technique for language prediction and how playing with the training material can greatly influence the resulting predictions. It is not only a matter of feeding the predictor with language, but also of making sure this language is useful for the kind of predictions we want to make. Does this also mean the computer really understands language? Probably not. It is just really fast in looking up comparable situations in the past and mimicking what happened next. Does that matter if the predictions are useful? That is up to y<span class=blink></span>"}]}