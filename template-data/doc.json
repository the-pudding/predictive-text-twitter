{"hed":"What text prediction teaches us about language","intro":[{"type":"text","value":"If you have ever typed something on a smartphone, you have used text prediction. In this article we will see how text predictors can work and how finding the best example language dataset is crucial for what kind of predictions come out. To see how this all works, we will try to predict tweets by four famous Twitter users."},{"type":"text","value":"To be able to make useful predictions, a text predictor needs as much knowledge about language as possible. Adding this knowledge by hand would be an enormous task, so this is often done by <em>machine learning</em>. These days, machine learning algorithms called <em>neural networks</em> are the best at text prediction, because of their remarkable ability to <a target=_blank href=http://bionlp-www.utu.fi/wv_demo/>capture meaning in a list of numbers</a> and to learn about the <a target=_blank href=https://chunml.github.io/ChunML.github.io/project/Creating-Text-Generator-Using-Recurrent-Neural-Network/>hierarchical levels of language</a> (from letters, to syllables, to words, phrases, sentences, etc). The downside, however, is that they can be pretty difficult to grasp - understanding why neural networks do the things they do is a <a target=_blank href=https://distill.pub/2018/building-blocks/>whole research field on its own</a>."},{"type":"text","value":"Fortunately, there are surprisingly effective machine learning techniques that are much simpler, so we can have some insight in what is happening under the hood. For example, the algorithm <em>k Nearest Neighbours</em> works by looking at the last few words you wrote, comparing these to all groups of words seen during the training phase, and giving as the best guess what followed groups of similar words in the past. Let us see how that works for the tweets of 4 <a target=_blank href=https://en.wikipedia.org/wiki/List_of_most-followed_Twitter_accounts#Top_50_accounts>of the most followed Twitter users on Earth</a>."},{"type":"text","value":"You can interact and play around with <em>k Nearest Neighbours</em> in the panel below. After you have chosen a tweet, you can move the slider to various positions in the text, and it will automatically detect the last combination of three words, a so-called <em>trigram</em>. Next, it will try to find similar trigrams in its database of trigrams (which was created based on all tweets by this user) and display that along with the word that most often followed this trigram."}],"textblock2-before":[{"type":"text","value":"This approach to text prediction is called <em>context sensitive</em>. A downside of this technique is that there often is no similar group of words available to make a prediction. To go from this to a text predictor that would be good enough to be used in practice, we need two more things:"}],"textblock2-bullets":[{"type":"text","value":"A list of words frequently used by the author, to be used as a backup."},{"type":"text","value":"Limiting the pool of probable predictions based on what the user already typed so far. For example, it makes no sense to predict a word like 'the' if the user already started typing 'ca'."}],"textblock2-after":[{"type":"text","value":"The resulting predictor is based on what you could call a very simple statistical language model. It is built entirely of example language data: if you put in different data, you get another model with other predictions. You can see that clearly if you let the models of our four celebrities predict each other's tweets:"}],"textblock3":[{"type":"text","value":"As you can tell when you play around for a while, the model of the user itself is the one that makes the correct prediction most often. This follows from the more general phenomenon in machine learning that the more similar the training data is to the production data, the better the results will be. Or, more simply: nobody writes more like you than you, so you are your own best language predictor."},{"type":"text","value":"Instead of just eyeballing which model works better, we can actually measure it and count the number of correctly guessed characters. You could argue that we are too harsh on ourselves if we count this way, as most language prediction apps give multiple options, but it is at least a good approximation to compare language models with each other. Let us see the percentages below as lower boundaries of what is possible with this technique."}],"textblock4-before":[{"type":"text","value":"Here too, we see that the more similar two Twitter users are, the more likely they are to correctly predict each other's tweets: the two singers Justin Timberlake and Lady Gaga are each other's best predictors. Barack Obama and Kim Kardashian, on the other hand, two people who got famous for completely different things, are each other's worst predictors. In other words, if we want to guess what a person is going to write next, our best guess is something similar to what this same person has written in the past. That is also why Twitter is the perfect resource to show the power of this idea: it is effectively a huge collection of language organized per author."},{"type":"text","value":"On the level of individual tweets, something else might strike your eye too: the statements above are not true for each tweet. For example, Kim Kardashian's tweet about 'working together with organizations' was predicted better by the language model of Barack Obama than her own. In other words, 'You are your own best language predictor' is more of a tendency than a hard rule, but as long as you try it on enough tweets you will see that it holds most of the time."},{"type":"text","value":"Our example users so far have been really active Twitter users with thousands of Tweets. We do not have that much material for most people, however. How do we solve that? We have learned above that we need example language as similar to the language we are trying to predict... but where do we find language that we did not produce ourselves, but is still similar to our own? The research field of sociolinguistics has the answer: the language from the people around you. It is a well known fact that people who talk to each other a lot tend to speak alike, and it is something that could be very useful in this case."},{"type":"text","value":"Is there also a way to simulate this effect in our experiments predicting tweets? It looks like it: 'people who talk to each other a lot' can be approximated on Twitter by following the @ mentions. These are the conversation participants of our example Twitter users that they mentioned most frequently (more than 10 times):"}],"textblock4-bullets":[{"type":"<strong>BarackObama</strong>","value":"VP (17 mentions)"},{"type":"<strong>jtimberlake</strong>","value":"ChrisStapleton (16 mentions), AnnaKendrick47 (15 mentions), jimmyfallon (15 mentions)"},{"type":"<strong>KimKardashian</strong>","value":"MakeupByMario (18 mentions), khloekardashian (13 mentions)"},{"type":"<strong>ladygaga</strong>","value":"itstonybennett (30 mentions), MarkRonson (16 mentions), faspiras (15 mentions)"}],"textblock4-after":[{"type":"text","value":"How much 'friends' a Twitter user has in this definition is of course highly dependent on the way he or she uses Twitter; whereas Lady Gaga and Justin Timberlake often address colleagues and other celebrities, Barack Obama almost exclusively uses Twitter address larger groups of people."},{"type":"text","value":"Big question now is: how do these 'friend' (or in the case of Khlo&eacute; Kardashian: 'sister') models perform? Judge for yourself:"}],"closing":[{"type":"text","value":"As you can see, the 'friend' models are ranked directly below the personal models in almost all cases. Part of this effect can of course be explained by overlapping topics; the models of Justin Timberlake and Lady Gaga are probably good at predicting each other's tweets because they are both tweeting about things like songs, concerts and fans. Something similar is probably happening with the predictions of @VP (Vice President) for the tweets of Obama: Obama only mentioned @VP when it was still being used by Joe Biden, but the tweets of current Vice President Mike Pence are still good predictors because of their political nature. Overlapping topics are not the whole story, though; research has shown that even if you take out all content words, leaving only words like 'the', 'but', 'and', 'is', etc, <a target=_blank href=http://www.aclweb.org/anthology/E/E14/E14-1034.pdf>tweets by friends are still better</a> <a target=_blank href=https://www.narcis.nl/publication/RecordID/oai%3Arepository.ubn.ru.nl%3A2066%2F155926/coll/person/id/5/Language/en>predictors than tweets by random people</a>."},{"type":"text","value":"Note that this technique makes it possible to make predictions of what somebody wants to say even if we have no previous material of a particular person at all. This can for example be the case if somebody has word finding problems (aphasia) or cannot move his/her speech organs (for example because of paralysis): a word predictor can be of great help to such a person, and can be trained with the language of the persons around him/her. This idea is called 'language transplantation'."},{"type":"text","value":"So there you have it: we have seen a simple technique for language prediction and how playing with the training material can greatly influence the predictions that come out. It is not only a matter of feeding the predictor with language, but also of making sure this language is useful for the kind of predictions we want to make. Does this also mean the computer really understands language? Probably not: it is just really fast in looking up comparable situations in the past and mimicking what happened next. Does that matter if the predictions are useful? That is up to y|..."}]}